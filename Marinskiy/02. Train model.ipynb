{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iPhone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*by Alexander Marinskiy*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, I decided to use the Resnet18 architecture. It shows good accuracy and at the same time it trains reasonable time. By default, the Resnet18 architecture is not represented in keras, so this repository on the github was used: https://github.com/qubvel/classification_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# install the nessesary package\n",
    "!pip install git+https://github.com/qubvel/classification_models.git\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from classification_models.resnet import ResNet18\n",
    "from tensorflow.contrib import lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to load pre-trained model because it might be a good starting point to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-tained Resnet18 model\n",
    "model = ResNet18(input_shape=(224,224,3), weights='imagenet', include_top=True)\n",
    "\n",
    "# change the last layer\n",
    "model.layers.pop()\n",
    "last = model.layers[-1].output\n",
    "x = Dense(2, activation=\"softmax\")(last)\n",
    "model = Model(model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model with adam optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# define directories for train and test\n",
    "train_dir = 'iphones_dataset_train'\n",
    "validation_dir = 'iphones_dataset_val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to define ImageDataGenerators and add augmentation for training dataset. I used quite strong augmentation in order to avoid overfitting. For testing set I did't use augmentation, so that the test sample was as close as possible to the real data on which the model will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ImageDataGenerator for training set. I used strong augmentation + rescaling.\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., \n",
    "                                   rotation_range = 90,\n",
    "                                   width_shift_range = 0.25,\n",
    "                                   height_shift_range = 0.25,\n",
    "                                   brightness_range = [0.3, 1.5],    \n",
    "                                   shear_range = 0.4,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   channel_shift_range = 20,\n",
    "                                   vertical_flip = True,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Set ImageDataGenerator for testing set. Note that here I used just rescaling and didn't use any augmentation\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the example of augmented images:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/augmentation.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set flow_from_directory. The images are resized to 224*224 because it is the default size for Resnet18 architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50144 images belonging to 2 classes.\n",
      "Found 334 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow training images using train_datagen generator. \n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = 'categorical', \n",
    "                                                    target_size = (224, 224))     \n",
    "\n",
    "# Flow validation images using test_datagen generator. Here I set turned off shuffling so that sklearn metriks worked correctly.\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size  = batch_size,\n",
    "                                                         class_mode  = 'categorical', \n",
    "                                                         target_size = (224, 224),\n",
    "                                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training takes a lot of time, and the process can be interrupted for various technical reasons. To save the progress in training the model, I used checkpoints. I saved the model after each epoch when val_score improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "filepath=\"resnet18-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model using fit generator\n",
    "model.fit_generator(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = train_generator.samples // batch_size,\n",
    "            epochs = 100,\n",
    "            validation_steps = validation_generator.samples // batch_size,\n",
    "            verbose = 1,\n",
    "            callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compres the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turned out that GitHub does not accept files larger than 100 MB. In order to meet this restriction, I decided to use Tensorflow Lite, which is usually used for mobile devices. First of all, I converted the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alex\\Documents\\iphoneOrNot\\env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Alex\\Documents\\iphoneOrNot\\env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Alex\\Documents\\iphoneOrNot\\env\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:591: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From C:\\Users\\Alex\\Documents\\iphoneOrNot\\env\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 100 variables.\n",
      "INFO:tensorflow:Converted 100 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Converting keras model to tflite model\n",
    "converter = lite.TFLiteConverter.from_keras_model_file('model.hdf5')\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the **size of the model has decreased from 137 MB to 45 MB**, and such model can already be uploaded to the GitHab. Nevertheless, I would like to assess how much the quality of the model has deteriorated in the process of such conversion. For this, the Area under Percision Recall Curve metric will be used. It is the same metric that will be used for the final evaluation of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This part is work in progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_tensor = image.img_to_array(img)                    \n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         \n",
    "    img_tensor /= 255.\n",
    "    \n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99012274 0.00987723]]\n",
      "[[1.00000e+00 3.47368e-11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "# change the following line to feed into your own data.\n",
    "input_data = load_image(r'C:\\Users\\Alex\\Documents\\iphoneOrNot\\Marinskiy\\iphones_dataset_train\\iphone\\!_3G\\103.jpg')\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "\n",
    "# change the following line to feed into your own data.\n",
    "input_data = load_image(r'C:\\Users\\Alex\\Documents\\iphoneOrNot\\Marinskiy\\iphones_dataset_train\\iphone\\!_3G\\107.jpg')\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alex\\Documents\\iphoneOrNot\\env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Alex\\Documents\\iphoneOrNot\\env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "from keras.models import load_model\n",
    "model = load_model('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 3.4739916e-11]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(load_image(r'C:\\Users\\Alex\\Documents\\iphoneOrNot\\Marinskiy\\iphones_dataset_train\\iphone\\!_3G\\107.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
